
## Reading

- [1. 两个惊艳的python库：tqdm和retry][r5] ✔️
- [2. Python中断多重循环的几种思路][r8] ✔️
- [3. Python的多进程 multiprocessing 编程技巧][r10] ✔️✔️✔️
- [4. Linux下的误删大坑与简单的恢复技巧][r13] ✔️

## Important

- [4. 谈谈dropout][r15]
- [6. 训练集、验证集和测试集的意义][r18] ✔️✔️
- [7. 浅谈神经网络中激活函数的设计][r19] ✔️
- [8. 更别致的词向量模型(六)：代码、分享与结语][r20]
- [9. 重新写了之前的新词发现算法：更快更好的新词发现](https://kexue.fm/archives/6920)

**Basic**

- [1. 闲聊：神经网络与深度学习][r1] ✔️
- [2. 漫话模型|模型与选芒果][r2] ✔️
- [3. 新词发现的信息熵方法与实现][r3]
- [4. 从Boosting学习到神经网络：看山是山？][r4]



## 1. Data Science

- [1. 用bert4keras做三元组抽取](https://kexue.fm/archives/7161)
- [2. “非自回归”也不差：基于MLM的阅读理解问答](https://kexue.fm/archives/7148)
- [3. 万能的seq2seq：基于seq2seq的阅读理解问答](https://kexue.fm/archives/7115)
- [4. 基于Conditional Layer Normalization的条件文本生成](https://kexue.fm/archives/7124)
- [5. 分享一个slide：花式自然语言处理][18.2]
- [6. 《Attention is All You Need》浅读（简介+代码）][18.1]
- [7. 为节约而生：从标准Attention到稀疏Attention](https://kexue.fm/archives/6853)
- [8. 从语言模型到Seq2Seq：Transformer如戏，全靠Mask](https://kexue.fm/archives/6933)
- [9. BN究竟起了什么作用？一个闭门造车的分析](https://kexue.fm/archives/6992)


[18.1]: https://kexue.fm/archives/4765
[18.2]: https://kexue.fm/archives/4823

**久远的**

- [1. 基于双向LSTM和迁移学习的seq2seq核心实体识别][r6]
- [2. 词向量与Embedding究竟是怎么回事？][r7] 
- [5. RNN模型中输入的重要性的评估][r17]
- [3. 梯度下降和EM算法：系出同源，一脉相承][r11]

**action**

- [开源一版DGCNN阅读理解问答模型（Keras版）](https://kexue.fm/archives/6906)
 
## 1. Keras

- [1. 6个派生优化器的简单介绍及其实现][keras1]
- [2. Keras：Tensorflow的黄金标准][keras2]
- [3. “让Keras更酷一些！”：层与模型的重用技巧][keras3]
- [4. 自己实现了一个bert4keras][keras4]
- [5. seq2seq之双向解码][keras5]
- [6. Keras实现两个优化器：Lookahead和LazyOptimizer][keras6]
- [7. “让Keras更酷一些！”：层中层与mask][keras7]
- [8. 用时间换取效果：Keras梯度累积优化器][keras8]
- [9. “让Keras更酷一些！”：中间变量、权重滑动和安全生成器][keras9]
- [10. “让Keras更酷一些！”：分层的学习率和自由的梯度][keras10]
- [12. “让Keras更酷一些！”：随意的输出和灵活的归一化][keras12]
- [13. “让Keras更酷一些！”：小众的自定义优化器][keras13]
- [14. 玩转Keras之seq2seq自动生成标题][keras14]
- [15. “让Keras更酷一些！”：精巧的层与花式的回调][keras15]
- [16. 简明条件随机场CRF介绍（附带纯Keras实现）][keras16]
- [17. Keras版的Word2Vec][w2v_6]
- [18. Keras中自定义复杂的loss函数][keras18]

[keras1]: https://kexue.fm/archives/7094
[keras2]: https://kexue.fm/archives/7055
[keras3]: https://kexue.fm/archives/6985
[keras4]: https://kexue.fm/archives/6915
[keras5]: https://kexue.fm/archives/6877
[keras6]: https://kexue.fm/archives/6869
[keras7]: https://kexue.fm/archives/6810
[keras8]: https://kexue.fm/archives/6794
[keras9]: https://kexue.fm/archives/6575
[keras10]: https://kexue.fm/archives/6418
[keras12]: https://kexue.fm/archives/6311


[keras13]: https://kexue.fm/archives/5879
[keras14]: https://kexue.fm/archives/5861
[keras15]: https://kexue.fm/archives/5765
[keras16]: https://kexue.fm/archives/5542

[keras18]: https://kexue.fm/archives/4493


**article**

- [开学啦！咱们来做完形填空～（讯飞杯）][r16]
- [泰迪杯赛前培训之数据挖掘与建模“慢谈”][r12]
- [获取并处理中文维基百科语料][r9]

## 2. Minimum Entropy

- [基于最小熵原理的NLP库：nlp zero][minimum_entropy_4]
- [最小熵原理（五）：“层层递进”之社区发现与聚类][minimum_entropy_5]
- [最小熵原理（四）：“物以类聚”之从图书馆到词向量][minimum_entropy_4.1]
- [最小熵原理（三）：“飞象过河”之句模版和语言结构][minimum_entropy_3]
- [最小熵原理（二）：“当机立断”之词库构建][minimum_entropy_2]
- [最小熵原理（一）：无监督学习的原理][minimum_entropy_1]

[minimum_entropy_1]: https://kexue.fm/archives/5448
[minimum_entropy_2]: https://kexue.fm/archives/5476
[minimum_entropy_3]: https://kexue.fm/archives/5577
[minimum_entropy_4]: https://kexue.fm/archives/5597
[minimum_entropy_4.1]: https://kexue.fm/archives/6191
[minimum_entropy_5]: https://kexue.fm/archives/7006


**article**

- [ON-LSTM：用有序神经元表达层次结构](https://kexue.fm/archives/6621)
- [分享一次专业领域词汇的无监督挖掘](https://kexue.fm/archives/6540)
- [基于GRU和am-softmax的句子相似度模型](https://kexue.fm/archives/5743)
- [从SamplePairing到mixup：神奇的正则项](https://kexue.fm/archives/5693)
- [貌离神合的RNN与ODE：花式RNN简介](https://kexue.fm/archives/5643)

- [果壳中的条件随机场(CRF In A Nutshell)][r21]
- [从loss的硬截断、软化到focal loss][r22]
- [百度实体链接比赛后记：行为建模和实体链接](https://kexue.fm/archives/6919)

[r1]: https://kexue.fm/archives/3331
[r2]: https://kexue.fm/archives/3390

[r3]: https://kexue.fm/archives/3491

[r4]: https://kexue.fm/archives/3873
[r5]: https://kexue.fm/archives/3902

[r6]: https://kexue.fm/archives/3942

[r7]: https://kexue.fm/archives/4122
[r8]: https://kexue.fm/archives/4159

[r9]: https://kexue.fm/archives/4176
[r10]: https://kexue.fm/archives/4231

[r11]: https://kexue.fm/archives/4277
[r12]: https://kexue.fm/archives/4271

[r13]: https://kexue.fm/archives/4491

[r15]: https://kexue.fm/archives/4521

[r16]: https://kexue.fm/archives/4564
[r17]: https://kexue.fm/archives/4582
[r18]: https://kexue.fm/archives/4638
[r19]: https://kexue.fm/archives/4647

[r20]: https://kexue.fm/archives/4681

[r21]: https://kexue.fm/archives/4695
[r22]: https://kexue.fm/archives/4733

## 4. Sentiment Classification

- [1. 传统模型][w1] ✔️
- [2. 深度学习模型][w2] ✔️ [苏神推荐的CSDN深度学习的教程系列](https://blog.csdn.net/itplus/article/details/21905449)
- [3. 分词 OR 不分词][w3]
- [4. 更好的损失函数][w4]
- [x. 基于双向GRU和语言模型的视角情感分析][w.x.1] 
- [x. 记录一次半监督的情感分析][w.x.2] 

[w1]: https://kexue.fm/archives/3360
[w2]: https://kexue.fm/archives/3414
[w3]: https://kexue.fm/archives/3863
[w4]: https://kexue.fm/archives/4293

[w.x.1]: https://kexue.fm/archives/4118
[w.x.2]: https://kexue.fm/archives/4374

## 5. 不可思议的Word2Vec

- [1. 数学原理][w2v_1]
- [2. 训练好的模型][w2v_2]
- [3. 提取关键词][w2v_3]
- [4. 不一样的“相似”][w2v_4]
- [5. Tensorflow版的Word2Vec][w2v_5]
- [6. Keras版的Word2Vec][w2v_6]

[w2v_1]: https://kexue.fm/archives/4299
[w2v_2]: https://kexue.fm/archives/4304
[w2v_3]: https://kexue.fm/archives/4316
[w2v_4]: https://kexue.fm/archives/4368
[w2v_5]: https://kexue.fm/archives/4402
[w2v_6]: https://kexue.fm/archives/4515

## 6. SVD分解

- [1. 自编码器与人工智能][s1]
- [2. 为什么SVD意味着聚类？][s2]
- [3. 连Word2Vec都只不过是个SVD？][s3]

[s1]: https://kexue.fm/archives/4208
[s2]: https://kexue.fm/archives/4216
[s3]: https://kexue.fm/archives/4233

<!--
## 4. 中文分词系列

- [1. 基于AC自动机的快速分词][z1]
- [2. 基于切分的新词发现][z2]
- [3. 字标注法与HMM模型][z3]
- [4. 基于双向LSTM的seq2seq字标注][z4]
- [5. 基于语言模型的无监督分词][z5]
- [6. 基于全卷积网络的中文分词][z6]
- [7. 深度学习分词？只需一个词典！][z7]
- [8. 更好的新词发现算法][z8]
- [x. 轻便的深度学习分词系统：NNCWS v0.1][z.x.1]

[z1]: https://kexue.fm/archives/3908
[z2]: https://kexue.fm/archives/3913
[z3]: https://kexue.fm/archives/3922
[z4]: https://kexue.fm/archives/3924
[z5]: https://kexue.fm/archives/3956
[z.x.1]: https://kexue.fm/archives/4114
[z6]: https://kexue.fm/archives/4195
[z7]: https://kexue.fm/archives/4245
[z8]: https://kexue.fm/archives/4256
-->

## Reference

- [苏神-keras][tag=keras]
- [苏神-归档 kexue.fm/content.html][su-content]
- [苏神-信息时代-page11- kexue.fm/category/Big-Data/15/][su]

<!--- [CSDN: 学习是一种态度!][su-r1]-->

[su]: https://kexue.fm/category/Big-Data/11
[su-r1]: https://blog.csdn.net/itplus
[su-content]: https://kexue.fm/content.html
[tag=keras]: https://kexue.fm/content.html?tag=keras