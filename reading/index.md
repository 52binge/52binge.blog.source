
## Reading

- [1. 两个惊艳的python库：tqdm和retry][r5]
- [2. Python中断多重循环的几种思路][r8]
- [3. Python的多进程编程技巧][r10]
- [4. Linux下的误删大坑与简单的恢复技巧][r13]

**article**

- [开学啦！咱们来做完形填空～（讯飞杯）][r16]
- [泰迪杯赛前培训之数据挖掘与建模“慢谈”][r12]
- [获取并处理中文维基百科语料][r9]

## 1. 数据科学

- [1. 闲聊：神经网络与深度学习][r1]
- [2. 漫话模型|模型与选芒果][r2]
- [3. 新词发现的信息熵方法与实现][r3]
- [4. 从Boosting学习到神经网络：看山是山？][r4]

**article**

- [基于双向LSTM和迁移学习的seq2seq核心实体识别][r6]
- [词向量与Embedding究竟是怎么回事？][r7] 

- [梯度下降和EM算法：系出同源，一脉相承][r11]

- [Keras中自定义复杂的loss函数][r14]
- [谈谈dropout][r15]

- [RNN模型中输入的重要性的评估][r17]
- [训练集、验证集和测试集的意义][r18]
- [浅谈神经网络中激活函数的设计][r19]

- [更别致的词向量模型(六)：代码、分享与结语][r20]

- [果壳中的条件随机场(CRF In A Nutshell)][r21]
- [从loss的硬截断、软化到focal loss][r22]

[r1]: https://kexue.fm/archives/3331
[r2]: https://kexue.fm/archives/3390

[r3]: https://kexue.fm/archives/3491

[r4]: https://kexue.fm/archives/3873
[r5]: https://kexue.fm/archives/3902

[r6]: https://kexue.fm/archives/3942

[r7]: https://kexue.fm/archives/4122
[r8]: https://kexue.fm/archives/4159

[r9]: https://kexue.fm/archives/4176
[r10]: https://kexue.fm/archives/4231

[r11]: https://kexue.fm/archives/4277
[r12]: https://kexue.fm/archives/4271

[r13]: https://kexue.fm/archives/4491

[r14]: https://kexue.fm/archives/4493
[r15]: https://kexue.fm/archives/4521

[r16]: https://kexue.fm/archives/4564
[r17]: https://kexue.fm/archives/4582
[r18]: https://kexue.fm/archives/4638
[r19]: https://kexue.fm/archives/4647

[r20]: https://kexue.fm/archives/4681

[r21]: https://kexue.fm/archives/4695
[r22]: https://kexue.fm/archives/4733


## 2. 文本情感分类

- [1. 传统模型][w1]
- [2. 深度学习模型][w2]
- [3. 分词 OR 不分词][w3]
- [4. 更好的损失函数][w4]
- [x. 基于双向GRU和语言模型的视角情感分析][w.x.1] 
- [x. 记录一次半监督的情感分析][w.x.2] 

[w1]: https://kexue.fm/archives/3360
[w2]: https://kexue.fm/archives/3414
[w3]: https://kexue.fm/archives/3863
[w4]: https://kexue.fm/archives/4293

[w.x.1]: https://kexue.fm/archives/4118
[w.x.2]: https://kexue.fm/archives/4374

## 3. 不可思议的Word2Vec

- [1. 数学原理][w2v_1]
- [2. 训练好的模型][w2v_2]
- [3. 提取关键词][w2v_3]
- [4. 不一样的“相似”][w2v_4]
- [5. Tensorflow版的Word2Vec][w2v_5]
- [6. Keras版的Word2Vec][w2v_6]

[w2v_1]: https://kexue.fm/archives/4299
[w2v_2]: https://kexue.fm/archives/4304
[w2v_3]: https://kexue.fm/archives/4316
[w2v_4]: https://kexue.fm/archives/4368
[w2v_5]: https://kexue.fm/archives/4402
[w2v_6]: https://kexue.fm/archives/4515

## 4. SVD分解

- [1. 自编码器与人工智能][s1]
- [2. 为什么SVD意味着聚类？][s2]
- [3. 连Word2Vec都只不过是个SVD？][s3]

[s1]: https://kexue.fm/archives/4208
[s2]: https://kexue.fm/archives/4216
[s3]: https://kexue.fm/archives/4233

<!--
## 4. 中文分词系列

- [1. 基于AC自动机的快速分词][z1]
- [2. 基于切分的新词发现][z2]
- [3. 字标注法与HMM模型][z3]
- [4. 基于双向LSTM的seq2seq字标注][z4]
- [5. 基于语言模型的无监督分词][z5]
- [6. 基于全卷积网络的中文分词][z6]
- [7. 深度学习分词？只需一个词典！][z7]
- [8. 更好的新词发现算法][z8]
- [x. 轻便的深度学习分词系统：NNCWS v0.1][z.x.1]

[z1]: https://kexue.fm/archives/3908
[z2]: https://kexue.fm/archives/3913
[z3]: https://kexue.fm/archives/3922
[z4]: https://kexue.fm/archives/3924
[z5]: https://kexue.fm/archives/3956
[z.x.1]: https://kexue.fm/archives/4114
[z6]: https://kexue.fm/archives/4195
[z7]: https://kexue.fm/archives/4245
[z8]: https://kexue.fm/archives/4256
-->

## Reference

- [苏神-keras][tag=keras]
- [苏神-归档 kexue.fm/content.html][su-content]
- [苏神-信息时代-page11- kexue.fm/category/Big-Data/15/][su]

<!--- [CSDN: 学习是一种态度!][su-r1]-->

[su]: https://kexue.fm/category/Big-Data/11
[su-r1]: https://blog.csdn.net/itplus
[su-content]: https://kexue.fm/content.html
[tag=keras]: https://kexue.fm/content.html?tag=keras