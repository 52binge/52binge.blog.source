
## interview 整理

#### 1. spark, map vs flatMap

```scala
val textFile = sc.textFile("README.md")
textFile.flatMap(_.split(" ")) 
```

> 在这个示例中，flatMap就把包含多行数据的RDD，即[“a b c”, “”, “d”] ，转换为了一个包含多个单词的集合。实际上，flatMap相对于map多了的是[[“a”,”b”,”c”],[],[“d”]] => [“a”,”b”,”c”,”d”]这一步。


#### 2. sparlk, 常用算子

1、map算子
2、flatMap算子
3、mapPartitions算子
4、glom算子
5、union算子
6、cartesian算子
7、grouBy算子

#### 3. transformer


> 1. [十道海量数据处理面试题](https://blog.csdn.net/v_JULY_v/article/details/6279498)

<font color=#c7254e>**摘要心得5：**</font>  

#### 28 逻辑斯特回归为什么要对特征进行离散化。机器学习 ML模型 中等

@严林，本题解析来源：https://www.zhihu.com/question/31989952

在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：

> 0. 离散特征的增加和减少都很容易，易于模型的快速迭代；
> 1. 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；
> 2. 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；
> 3. 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；
> 4. 离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；
> 5. 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；
> 6. 特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。

<font color=#c7254e>**摘要心得8：**</font> 

#### 30 hash 冲突及解决办法。数据结构/算法 中等

@Sommer_Xia，来源：http://blog.csdn.net/shymi1991/article/details/39432775
关键字值不同的元素可能会映象到哈希表的同一地址上就会发生哈希冲突。

解决办法：

1）开放定址法：当冲突发生时，使用某种探查(亦称探测)技术在散列表中形成一个探查(测)序列。沿此序列逐个单元地查找，直到找到给定 的关键字，或者碰到一个开放的地址(即该地址单元为空)为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。查找时探查到开放的 地址则表明表中无待查的关键字，即查找失败。
2） 再哈希法：同时构造多个不同的哈希函数。
3）链地址法：将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。
4）建立公共溢出区：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。

**请简要介绍下tensorflow的计算图，深度学习 DL框架 中**

> Tensorflow 通过计算图的形式来表述计算的编程系统，计算图也叫数据流图，可把计算图看做是一种有向图.
> 
> Tensorflow 中的每一个节点都是计算图上的一个Tensor, 也就是张量，而节点之间的边描述了计算之间的依赖关系(定义时) 和 数学操作(运算时)。

<font color=#c7254e>**摘要心得10：**</font> 

**KNN中的K如何选取的？机器学习 ML模型 易**

KNN中的K值选取对K近邻算法的结果会产生重大影响。如李航博士的一书「统计学习方法」上所说：

> 1). 如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；  
> 
> 2). 如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。  
> 
> 3). K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。

> 在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。


### 2. [机器学习interview320道](https://blog.csdn.net/qq_33335553/article/details/80651017)
    
### 2. [机器学习常见面试题整理](http://kubicode.me/2015/08/16/Machine%20Learning/Common-Interview/)

### 3. [机器学习面试题总结](https://zhuanlan.zhihu.com/c_129612503)

### 5. [BAT机器学习面试1000题系列](https://blog.csdn.net/v_july_v/article/details/78121924)

## 工程架构

### 1. [47道机器学习常见面试题（上）](https://zhuanlan.zhihu.com/p/45091568)

### 2. [操作系统面试题](https://zhuanlan.zhihu.com/p/23755202)

### 3. [网络面试题](https://zhuanlan.zhihu.com/p/24001696)

### 4. [TCP/IP四层模型](http://www.cnblogs.com/BlueTzar/articles/811160.html)

### 5. [数据库篇](https://zhuanlan.zhihu.com/p/23713529?refer=passer)

### 6. [面试题](http://python.jobbole.com/85231/)

