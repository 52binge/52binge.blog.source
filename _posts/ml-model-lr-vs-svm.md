---
title: LR ä¸ SVM çš„å¼‚åŒ
toc: true
date: 2018-06-23 16:08:21
categories: machine-learning
tags: machine-learning
mathjax: true
---

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

LR å’Œ SVM ä¹‹é—´çš„ç›¸åŒç‚¹å’Œä¸åŒç‚¹, æŸ¥è¯¢äº†ç½‘ç»œä¸Šçš„ä¸€äº›èµ„æ–™ï¼Œç‰¹æ•´ç†æ±‡æ€»å¦‚ä¸‹ : ğŸ˜„

1. LR å’Œ SVM æ”¾åœ¨ä¸€èµ·æ¥è¿›è¡Œæ¯”è¾ƒ, whyï¼Ÿ
2. LR å’Œ SVM çš„ ç›¸åŒç‚¹å’Œä¸åŒç‚¹?

<!-- more -->
 
## 1. ä¸ºä»€ä¹ˆå°†LRå’ŒSVMæ”¾åœ¨ä¸€èµ·æ¥è¿›è¡Œæ¯”è¾ƒï¼Ÿ

å›ç­”è¿™ä¸ªé—®é¢˜å…¶å®å°±æ˜¯å›ç­”LRå’ŒSVMæœ‰ä»€ä¹ˆç›¸åŒç‚¹

### LR å’Œ SVM éƒ½æ˜¯åˆ†ç±»ç®—æ³•

> åˆ¤æ–­ä¸€ä¸ªç®—æ³•æ˜¯åˆ†ç±»è¿˜æ˜¯å›å½’ç®—æ³•çš„å”¯ä¸€æ ‡å‡†å°±æ˜¯æ ·æœ¬labelçš„ç±»å‹ï¼Œå¦‚æœlabelæ˜¯ç¦»æ•£çš„ï¼Œå°±æ˜¯åˆ†ç±»ç®—æ³•ï¼Œå¦‚æœlabelæ˜¯è¿ç»­çš„ï¼Œå°±æ˜¯å›å½’ç®—æ³•ã€‚å¾ˆæ˜æ˜¾ï¼ŒLRçš„è®­ç»ƒæ•°æ®çš„labelæ˜¯â€œ0æˆ–è€…1â€ï¼Œå½“ç„¶æ˜¯åˆ†ç±»ç®—æ³•.

### LR å’Œ SVM éƒ½æ˜¯çº¿æ€§åˆ†ç±»ç®—æ³• 

> å¦‚æœä¸è€ƒè™‘æ ¸å‡½æ•°ï¼ŒLRå’ŒSVMéƒ½æ˜¯çº¿æ€§åˆ†ç±»ç®—æ³•ï¼Œä¹Ÿå°±æ˜¯è¯´ä»–ä»¬çš„åˆ†ç±»å†³ç­–é¢éƒ½æ˜¯çº¿æ€§

> è¿™é‡Œè¦å…ˆè¯´æ˜ä¸€ç‚¹ï¼Œé‚£å°±æ˜¯LRä¹Ÿæ˜¯å¯ä»¥ç”¨æ ¸å‡½æ•°çš„ï¼Œè‡³äºä¸ºä»€ä¹ˆé€šå¸¸åœ¨SVMä¸­è¿ç”¨æ ¸å‡½æ•°è€Œä¸åœ¨LRä¸­è¿ç”¨ï¼Œåé¢è®²åˆ°ä»–ä»¬ä¹‹é—´åŒºåˆ«çš„æ—¶å€™ä¼šé‡ç‚¹åˆ†æã€‚æ€»ä¹‹ï¼ŒåŸå§‹çš„LRå’ŒSVMéƒ½æ˜¯çº¿æ€§åˆ†ç±»å™¨ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆé€šå¸¸æ²¡äººé—®ä½ å†³ç­–æ ‘å’ŒLRä»€ä¹ˆåŒºåˆ«ï¼Œå†³ç­–æ ‘å’ŒSVMä»€ä¹ˆåŒºåˆ«ï¼Œä½ è¯´ä¸€ä¸ªéçº¿æ€§åˆ†ç±»å™¨å’Œä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
> 
> 

### LR å’Œ SVM éƒ½æ˜¯åˆ¤åˆ«æ¨¡å‹

- | generative approach | discriminative approach
---- | :----: | :----:
å®šä¹‰ | ç”±æ•°æ®å­¦ä¹ è”åˆæ¦‚ç‡åˆ†å¸ƒ$P(X,Y)$ ç„¶å,<br>æ±‚å‡ºåœ¨$X$æƒ…å†µä¸‹ï¼Œ$P(Y)$ä½œä¸ºé¢„æµ‹çš„æ¨¡å‹ | å†³ç­–å‡½æ•°$f(x)$æˆ–æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ$P(X)$ä½œä¸ºé¢„æµ‹æ¨¡å‹
ç‰¹ç‚¹ | 1. å¯è¿˜åŸå‡º$P(X,Y)$ï¼›<br> 2. å­¦ä¹ æ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼›<br> 3. å­˜åœ¨éšå˜é‡æ—¶ä»å¯ç”¨ | 1. ç›´æ¥é¢å¯¹é¢„æµ‹ï¼Œå‡†ç¡®ç‡æ›´é«˜äº›; <br> 2. ä¾¿äºæ•°æ®æŠ½è±¡ï¼Œç‰¹å¾å®šä¹‰ä½¿ç”¨;
æ¨¡å‹ | native bayesã€hidden markov	| Logistic Regressionã€SVMã€Gradient Boostingã€CRF.. 
Note | ç»™å®šè¾“å…¥$X$äº§ç”Ÿè¾“å‡º$Y$çš„ç”Ÿæˆå…³ç³» | å¯¹ç»™å®šçš„è¾“å…¥$X$ï¼Œåº”é¢„æµ‹ä»€ä¹ˆæ ·çš„è¾“å‡º$Y$


> **discriminative model** åˆ¤åˆ«æ¨¡å‹ä¸å…³å¿ƒæ•°æ®æ˜¯æ€ä¹ˆç”Ÿæˆçš„ï¼Œå…³å¿ƒä¿¡å·ä¹‹é—´çš„å·®åˆ«ï¼Œåç”¨å·®åˆ«æ¥å¯¹ç»™å®šçš„ä¸€ä¸ªä¿¡å·è¿›è¡Œåˆ†ç±»
> å¸¸è§çš„åˆ¤åˆ«æ¨¡å‹æœ‰ï¼šKNNã€SVMã€LR

## 2. LR å’Œ SVM çš„ ä¸åŒ

1. Linear SVM å’Œ LR éƒ½æ˜¯çº¿æ€§åˆ†ç±»å™¨
2. Linear SVM ä¸ç›´æ¥ä¾èµ–æ•°æ®åˆ†å¸ƒï¼Œåˆ†ç±»å¹³é¢ä¸å—ä¸€éƒ¨åˆ†æ ·æœ¬ç‚¹å½±å“ï¼›LRåˆ™å—æ‰€æœ‰æ•°æ®ç‚¹çš„å½±å“ï¼Œå¦‚æœæ•°æ®ä¸åŒç±»åˆ«strongly unbalanceä¸€èˆ¬éœ€è¦å…ˆå¯¹æ•°æ®åšbalancingã€‚
3. Linear SVM ä¾èµ–æ•°æ®è¡¨è¾¾çš„è·ç¦»æµ‹åº¦ï¼Œæ‰€ä»¥éœ€è¦å¯¹æ•°æ®å…ˆåšnormalizationï¼›LRä¸å—å…¶å½±å“
4. Linear SVM ä¾èµ–penaltyçš„ç³»æ•°ï¼Œå®éªŒä¸­éœ€è¦åšvalidation
5. Linear SVM å’Œ LR çš„ performance éƒ½ä¼šæ”¶åˆ°outlierçš„å½±å“ï¼Œå…¶æ•æ„Ÿç¨‹åº¦è€Œè¨€ï¼Œè°æ›´å¥½å¾ˆéš¾ä¸‹æ˜ç¡®ç»“è®º.

## 3. SVM å’Œ LR çš„æ¯”è¾ƒ

ä¸¤ç§æ–¹æ³•éƒ½æ˜¯å¸¸è§çš„åˆ†ç±»ç®—æ³•ï¼Œä»ç›®æ ‡å‡½æ•°æ¥çœ‹ï¼ŒåŒºåˆ«åœ¨äºé€»è¾‘å›å½’é‡‡ç”¨çš„æ˜¯logistical lossï¼Œsvmé‡‡ç”¨çš„æ˜¯hinge lossã€‚è¿™ä¸¤ä¸ªæŸå¤±å‡½æ•°çš„ç›®çš„éƒ½æ˜¯**å¢åŠ å¯¹åˆ†ç±»å½±å“è¾ƒå¤§çš„æ•°æ®ç‚¹çš„æƒé‡ï¼Œå‡å°‘ä¸åˆ†ç±»å…³ç³»è¾ƒå°çš„æ•°æ®ç‚¹çš„æƒé‡**ã€‚

SVM çš„å¤„ç†æ–¹æ³•æ˜¯åªè€ƒè™‘support vectorsï¼Œä¹Ÿå°±æ˜¯å’Œåˆ†ç±»æœ€ç›¸å…³çš„å°‘æ•°ç‚¹ï¼Œå»å­¦ä¹ åˆ†ç±»å™¨ã€‚è€ŒLRé€šè¿‡éçº¿æ€§æ˜ å°„ï¼Œå¤§å¤§å‡å°äº†ç¦»åˆ†ç±»å¹³é¢è¾ƒè¿œçš„ç‚¹çš„æƒé‡ï¼Œç›¸å¯¹æå‡äº†ä¸åˆ†ç±»æœ€ç›¸å…³çš„æ•°æ®ç‚¹çš„æƒé‡ã€‚ä¸¤è€…çš„æ ¹æœ¬ç›®çš„éƒ½æ˜¯ä¸€æ ·çš„ã€‚æ­¤å¤–ï¼Œæ ¹æ®éœ€è¦ï¼Œä¸¤ä¸ªæ–¹æ³•éƒ½å¯ä»¥å¢åŠ ä¸åŒçš„æ­£åˆ™åŒ–é¡¹ï¼Œå¦‚l1,l2ç­‰ç­‰ã€‚æ‰€ä»¥åœ¨å¾ˆå¤šå®éªŒä¸­ï¼Œä¸¤ç§ç®—æ³•çš„ç»“æœæ˜¯å¾ˆæ¥è¿‘çš„ã€‚

LR ç›¸å¯¹æ¥è¯´æ¨¡å‹æ›´ç®€å•ï¼Œå¥½ç†è§£ï¼Œå®ç°èµ·æ¥ï¼Œç‰¹åˆ«æ˜¯å¤§è§„æ¨¡çº¿æ€§åˆ†ç±»æ—¶æ¯”è¾ƒæ–¹ä¾¿ã€‚è€ŒSVMçš„ç†è§£å’Œä¼˜åŒ–ç›¸å¯¹æ¥è¯´å¤æ‚ä¸€äº›ã€‚ä½†æ˜¯SVMçš„ç†è®ºåŸºç¡€æ›´åŠ ç‰¢å›ºï¼Œæœ‰ä¸€å¥—ç»“æ„åŒ–é£é™©æœ€å°åŒ–çš„ç†è®ºåŸºç¡€ï¼Œè™½ç„¶ä¸€èˆ¬ä½¿ç”¨çš„äººä¸å¤ªä¼šå»å…³æ³¨ã€‚è¿˜æœ‰å¾ˆé‡è¦çš„ä¸€ç‚¹ï¼ŒSVMè½¬åŒ–ä¸ºå¯¹å¶é—®é¢˜åï¼Œåˆ†ç±»åªéœ€è¦è®¡ç®—ä¸å°‘æ•°å‡ ä¸ªæ”¯æŒå‘é‡çš„è·ç¦»ï¼Œè¿™ä¸ªåœ¨è¿›è¡Œå¤æ‚æ ¸å‡½æ•°è®¡ç®—æ—¶ä¼˜åŠ¿å¾ˆæ˜æ˜¾ï¼Œèƒ½å¤Ÿå¤§å¤§ç®€åŒ–æ¨¡å‹å’Œè®¡ç®—é‡ã€‚

### LR & SVM ä¸åŒç‚¹

> è¦è¯´æœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Œé‚£å°±æ˜¯ä¸¤ä¸ªæ¨¡å‹å¯¹æ•°æ®å’Œå‚æ•°çš„æ•æ„Ÿç¨‹åº¦ä¸åŒ

model | desc
:----: | :----:
**Linear SVM** | æ¯”è¾ƒä¾èµ– penaltyçš„ç³»æ•° å’Œ æ•°æ®è¡¨è¾¾ç©ºé—´çš„æµ‹åº¦
**LR(è‡ªå¸¦æ­£åˆ™é¡¹)** | æ¯”è¾ƒä¾èµ–å¯¹å‚æ•°åš L1 regularization çš„ç³»æ•°

> ä½†æ˜¯ç”±äºä»–ä»¬æˆ–å¤šæˆ–å°‘éƒ½æ˜¯çº¿æ€§åˆ†ç±»å™¨ï¼Œæ‰€ä»¥å®é™…ä¸Šå¯¹ä½ç»´åº¦æ•°æ®overfittingçš„èƒ½åŠ›éƒ½æ¯”è¾ƒæœ‰é™ï¼Œç›¸æ¯”ä¹‹ä¸‹å¯¹é«˜ç»´åº¦æ•°æ®ï¼ŒLRçš„è¡¨ç°ä¼šæ›´åŠ ç¨³å®šï¼Œä¸ºä»€ä¹ˆå‘¢ï¼Ÿ

> å› ä¸ºLinear SVMåœ¨è®¡ç®—marginæœ‰å¤šâ€œå®½â€çš„æ—¶å€™æ˜¯ä¾èµ–æ•°æ®è¡¨è¾¾ä¸Šçš„è·ç¦»æµ‹åº¦çš„ï¼Œæ¢å¥è¯è¯´å¦‚æœè¿™ä¸ªæµ‹åº¦ä¸å¥½ï¼ˆbadly scaledï¼Œè¿™ç§æƒ…å†µåœ¨é«˜ç»´æ•°æ®å°¤ä¸ºæ˜¾è‘—ï¼‰ï¼Œæ‰€æ±‚å¾—çš„æ‰€è°“Large marginå°±æ²¡æœ‰æ„ä¹‰äº†ï¼Œè¿™ä¸ªé—®é¢˜å³ä½¿æ¢ç”¨kernel trickï¼ˆæ¯”å¦‚ç”¨Gaussian kernelï¼‰ä¹Ÿæ— æ³•å®Œå…¨é¿å…ã€‚

> æ‰€ä»¥ä½¿ç”¨**Linear SVM**éƒ½éœ€è¦å…ˆå¯¹æ•°æ®åš**normalization**ï¼Œè€Œæ±‚è§£LRï¼ˆwithout regularizationï¼‰æ—¶åˆ™ä¸éœ€è¦æˆ–è€…ç»“æœä¸æ•æ„Ÿã€‚

> æ³¨ï¼šä¸å¸¦æ­£åˆ™åŒ–çš„LRï¼Œå…¶åšnormalizationçš„ç›®çš„æ˜¯ä¸ºäº†æ–¹ä¾¿é€‰æ‹©ä¼˜åŒ–è¿‡ç¨‹çš„èµ·å§‹å€¼ï¼Œä¸ä»£è¡¨æœ€åçš„è§£çš„performanceä¼šè·Ÿnormalizationç›¸å…³ï¼Œè€Œå…¶çº¿æ€§çº¦æŸæ˜¯å¯ä»¥è¢«æ”¾ç¼©çš„ï¼ˆç­‰å¼ä¸¤è¾¹å¯åŒæ—¶ä¹˜ä»¥ä¸€ä¸ªç³»æ•°ï¼‰ï¼Œæ‰€ä»¥åšnormalizationåªæ˜¯ä¸ºäº†æ±‚è§£ä¼˜åŒ–æ¨¡å‹è¿‡ç¨‹ä¸­æ›´å®¹æ˜“é€‰æ‹©åˆå§‹å€¼ã€‚

### loss function

> å…·ä½“åˆ° loss function ä¸Šæ¥çœ‹ï¼Œ LR ç”¨çš„æ˜¯ `log-loss`, SVM ç”¨çš„æ˜¯ `hinge-loss`, ä¸¤è€…çš„ç›¸ä¼¼ä¹‹å¤„åœ¨äº loss åœ¨é”™è¯¯åˆ†ç±»çš„æ—¶å€™éƒ½å¾ˆå¤§ï¼Œä½†æ˜¯å¯¹äºæ­£ç¡®åˆ†ç±»çš„ç‚¹ï¼Œhinge-loss å°±ä¸ç®¡äº†ï¼Œè€Œ log-loss è¿˜è¦è€ƒè™‘è¿›å»ã€‚æ­¤å¤–å› ä¸º log-loss åœ¨ mis-classified çš„ç‚¹ä¸Šæ˜¯æŒ‡æ•°çº§å¢é•¿çš„ï¼Œè€Œ hinge-loss æ˜¯çº¿æ€§å¢é•¿ï¼Œæ‰€ä»¥ **LR åœ¨å¶å°”å‡ºç° mis-label çš„æƒ…å†µä¸‹çš„è¡¨ç°ä¼šæ¯”è¾ƒç³Ÿç³•**ã€‚

> å¦å¤– regularization åœ¨è¿™é‡Œæ²¡æœ‰åŒºåˆ«ï¼ŒL1/L2 ä¸¤ä¸ªéƒ½èƒ½ç”¨ï¼Œæ•ˆæœä¹Ÿå·®ä¸å¤šã€‚Class imbalance çš„è¯ SVM ä¸€èˆ¬ç”¨ weight è§£å†³ï¼ŒLR å› ä¸ºå¯ä»¥é¢„æµ‹æ¦‚ç‡ï¼Œæ‰€ä»¥ä¹Ÿå¯ä»¥ç›´æ¥å¯¹æœ€åçš„ç»“æœè¿›è¡Œè°ƒæ•´ï¼Œå–ä¸åŒçš„é˜ˆå€¼æ¥è¾¾åˆ°ç†æƒ³çš„æ•ˆæœã€‚

> å®è·µä¸­ LR çš„é€Ÿåº¦æ˜æ˜¾æ›´å¿«ï¼Œç»´åº¦å°çš„æ—¶å€™ bias å° ä¹Ÿä¸å®¹æ˜“ overfit. ç›¸å Kernel SVM åœ¨å¤§è§„æ¨¡æ•°æ®é›†çš„æƒ…å†µä¸‹åŸºæœ¬ä¸å®ç”¨ï¼Œä½†æ˜¯å¦‚æœæ•°æ®é›†æœ¬èº«æ¯”è¾ƒå°è€Œä¸”ç»´åº¦é«˜çš„çš„è¯ä¸€èˆ¬ SVM è¡¨ç°æ›´å¥½ã€‚

## 4. LR & SVM é€‰å‹

åœ¨Andrew NGçš„è¯¾é‡Œè®²åˆ°è¿‡ï¼š

1. å¦‚æœFeatureçš„æ•°é‡å¾ˆå¤§ï¼Œè·Ÿæ ·æœ¬æ•°é‡å·®ä¸å¤šï¼Œè¿™æ—¶å€™é€‰ç”¨LRæˆ–è€…æ˜¯Linear Kernelçš„SVM
2. å¦‚æœFeatureçš„æ•°é‡æ¯”è¾ƒå°ï¼Œæ ·æœ¬æ•°é‡ä¸€èˆ¬ï¼Œä¸ç®—å¤§ä¹Ÿä¸ç®—å°ï¼Œé€‰ç”¨SVM+Gaussian Kernel
3. å¦‚æœFeatureçš„æ•°é‡æ¯”è¾ƒå°ï¼Œè€Œæ ·æœ¬æ•°é‡å¾ˆå¤šï¼Œéœ€è¦æ‰‹å·¥æ·»åŠ ä¸€äº›featureå˜æˆç¬¬ä¸€ç§æƒ…å†µ


## Reference article

- [LR ä¸ SVMçš„å¼‚åŒ][1]
- [æ‡’æ­»éª†é©¼ - ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ç¬”è®°(ä¸€)][2]
- [çŸ¥ä¹ : æœ€å°äºŒä¹˜ã€æå¤§ä¼¼ç„¶ã€æ¢¯åº¦ä¸‹é™æœ‰ä½•åŒºåˆ«ï¼Ÿ][3]
- [çŸ¥ä¹ : Linear SVM å’Œ LR æœ‰ä»€ä¹ˆå¼‚åŒï¼Ÿ][4]
- [ç™½å¼€æ°´åŠ ç³– SVMä¸LRçš„æ¯”è¾ƒ][5]
- [æ‡’æ­»éª†é©¼ - å£è¿°æ¨¡å‹æ•´ç†][6]

[img1]: /images/svm/svm-1-1.jpg


[1]: https://www.cnblogs.com/zhizhan/p/5038747.html
[2]: http://izhaoyi.top/2017/06/02/Note-StatisticalML/
[3]: https://www.zhihu.com/question/24900876
[4]: https://www.zhihu.com/question/26768865/answer/139613835
[5]: http://www.cnblogs.com/peizhe123/p/5674730.html
[6]: http://izhaoyi.top/2017/09/03/model-pre/


