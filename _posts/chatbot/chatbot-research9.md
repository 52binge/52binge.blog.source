---
title: Chatbot Research 9 - æ—§ç‰ˆ tf.contrib.legacy_seq2seq API ä»‹ç»
toc: true
date: 2017-11-19 14:00:21
categories: chatbot
tags: tf.contrib.legacy_seq2seq
mathjax: true
---

æœ‰äº†å¯¹ä»£ç çš„æ·±å±‚æ¬¡ç†è§£ï¼Œæˆ‘ä»¬ä¹‹åæ„å»º Chatbot ç³»ç»Ÿçš„æ—¶å€™æœ‰å¾ˆå¤§çš„å¸®åŠ©ã€‚

<!-- more -->

> æ—§çš„seq2seqæ¥å£ä¹Ÿå°±æ˜¯tf.contrib.legacy_seq2seqä¸‹çš„é‚£éƒ¨åˆ†ï¼Œæ–°çš„æ¥å£åœ¨tf.contrib.seq2seqä¸‹ã€‚
>
> æ–°seq2seqæ¥å£ä¸æ—§çš„ç›¸æ¯”æœ€ä¸»è¦çš„åŒºåˆ«æ˜¯å®ƒæ˜¯åŠ¨æ€å±•å¼€çš„ï¼Œè€Œæ—§çš„æ˜¯é™æ€å±•å¼€çš„ã€‚
>
> é™æ€å±•å¼€(static unrolling) ï¼šæŒ‡çš„æ˜¯å®šä¹‰æ¨¡å‹åˆ›å»ºgraphçš„æ—¶å€™ï¼Œåºåˆ—çš„é•¿åº¦æ˜¯å›ºå®šçš„ï¼Œä¹‹åä¼ å…¥çš„æ‰€æœ‰åºåˆ—éƒ½å¾—æ˜¯å®šä¹‰æ—¶æŒ‡å®šçš„é•¿åº¦ã€‚è¿™æ ·æ‰€æœ‰çš„å¥å­éƒ½è¦paddingåˆ°æŒ‡å®šçš„é•¿åº¦ï¼Œå¾ˆæµªè´¹å­˜å‚¨ç©ºé—´ï¼Œè®¡ç®—æ•ˆç‡ä¹Ÿä¸é«˜ã€‚ä½†æƒ³å¤„ç†å˜é•¿åºåˆ—ï¼Œä¹Ÿæ˜¯æœ‰åŠæ³•çš„ï¼Œéœ€è¦é¢„å…ˆæŒ‡å®šä¸€ç³»åˆ—çš„bucketsï¼Œå¦‚

## å‡½æ•°éƒ¨åˆ†

[æ—§ç‰ˆlegacy_seq2seqä»£ç ][2]

é¦–å…ˆçœ‹ä¸€ä¸‹è¿™ä¸ªæ–‡ä»¶çš„ç»„æˆï¼Œä¸»è¦åŒ…å«ä¸‹é¢å‡ ä¸ªå‡½æ•°ï¼š

> - def _extract\_argmax\_and\_embed(embedding, ...
> - def rnn\_decoder(decoder\_inputs, initial\_state, ...
> - def basic\_rnn\_seq2seq(encoder\_inputs, ... 
> - def tied\_rnn\_seq2seq(encoder\_inputs, ...
> - def embedding\_rnn\_seq2seq(encoder\_inputs, ...
> - def embedding\_tied\_rnn\_seq2seq(encoder\_inputs, ...
> - def attention\_decoder(decoder_inputs, ...
> - def embedding\_attention\_decoder(decoder\_inputs, ...
> - def embedding\_attention\_seq2seq(encoder\_inputs, ...
> - def one2many\_rnn\_seq2seq(encoder\_inputs, ...
> - def sequence\_loss\_by\_example(logits, ...
> - def sequence\_loss(logits, ...
> - def model\_with\_buckets(encoder\_inputs, ...

**å¯ä»¥çœ‹åˆ°æŒ‰ç…§è°ƒç”¨å…³ç³»å’ŒåŠŸèƒ½ä¸åŒå¯ä»¥åˆ†æˆä¸‹é¢çš„ç»“æ„**ï¼š

```py
model_with_buckets
â”‚
â”œâ”€â”€ seq2seqå‡½æ•°
â”‚   
â”‚Â Â  â”œâ”€â”€ basic_rnn_seq2seq
â”‚Â Â  â”‚   â”œâ”€â”€ rnn_decoder
â”‚Â Â  â””â”€â”€ tied_rnn_seq2seq
â”‚Â Â  â”œâ”€â”€ embedding_tied_rnn_seq2seq
â”‚Â Â  â””â”€â”€ embedding_rnn_seq2seq
â”‚   â”‚   â”œâ”€â”€ embedding_rnn_decoder
â”‚Â Â  â”œâ”€â”€ embedding_attention_seq2seq
â”‚   â”‚   â”œâ”€â”€ embedding_attention_decoder
â”‚   â”‚   â”‚   â”œâ”€â”€ attention_decoder
â”‚   â”‚   â”‚   â”œâ”€â”€ attention
â”‚Â Â  â””â”€â”€ one2many_rnn_seq2seq
â”‚   
â””â”€â”€ losså‡½æ•°
    â”œâ”€â”€ sequence_loss_by_example
    â”œâ”€â”€ sequence_loss
```

### model_with_buckets()å‡½æ•°

```py
def model_with_buckets(encoder_inputs,
                      decoder_inputs,
                      targets,
                      weights,
                      buckets,
                      seq2seq,
                      softmax_loss_function=None,
                      per_example_loss=False,
                      name=None):
```

è¿™ä¸ªå‡½æ•°ï¼Œç›®çš„æ˜¯ä¸ºäº†å‡å°‘è®¡ç®—é‡å’ŒåŠ å¿«æ¨¡å‹è®¡ç®—é€Ÿåº¦ï¼Œç„¶åç”±äºè¿™éƒ¨åˆ†ä»£ç æ¯”è¾ƒå¤è€ï¼Œä½ ä¼šå‘ç°æœ‰äº›åœ°æ–¹è¿˜åœ¨ä½¿ç”¨static_rnn()è¿™ç§å‡½æ•°ï¼Œå…¶å®æ–°ç‰ˆçš„tfä¸­å¼•å…¥dynamic_rnnä¹‹åå°±ä¸éœ€è¦è¿™ä¹ˆåšäº†ã€‚

åˆ†æä¸€ä¸‹ï¼Œå…¶å®æ€è·¯å¾ˆç®€å•ï¼Œå°±æ˜¯å°†è¾“å…¥é•¿åº¦åˆ†æˆä¸åŒçš„é—´éš”ï¼Œè¿™æ ·æ•°æ®çš„åœ¨å¡«å……æ—¶åªéœ€è¦å¡«å……åˆ°ç›¸åº”çš„bucketé•¿åº¦å³å¯ï¼Œä¸éœ€è¦éƒ½å¡«å……åˆ°æœ€å¤§é•¿åº¦ã€‚

æ¯”å¦‚ buckets å– `[(5ï¼Œ10), (10ï¼Œ20),(20ï¼Œ30)...]` æ¯ä¸ª bucket çš„

1. ç¬¬ä¸€ä¸ªæ•°å­—è¡¨ç¤º source å¡«å……çš„é•¿åº¦
2. ç¬¬äºŒä¸ªæ•°å­—è¡¨ç¤º target å¡«å……çš„é•¿åº¦

ä¸¾ä¸ªğŸŒ° egï¼š**â€˜æˆ‘çˆ±ä½ â€™-->â€˜I love youâ€™**ï¼Œ åº”è¯¥ä¼šè¢«åˆ†é…åˆ°ç¬¬ä¸€ä¸ªbucketä¸­

ç„¶åâ€˜æˆ‘çˆ±ä½ â€™ä¼šè¢«padæˆé•¿åº¦ä¸º5çš„åºåˆ—ï¼Œâ€˜I love youâ€™ä¼šè¢«padæˆé•¿åº¦ä¸º10çš„åºåˆ—ã€‚å…¶å®å°±æ˜¯æ¯ä¸ªbucketè¡¨ç¤ºä¸€ä¸ªæ¨¡å‹çš„å‚æ•°é…ç½®ã€‚è¿™æ ·å¯¹æ¯ä¸ªbucketéƒ½æ„é€ ä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åè®­ç»ƒæ—¶å–ç›¸åº”é•¿åº¦çš„åºåˆ—è¿›è¡Œï¼Œè€Œè¿™äº›æ¨¡å‹å°†ä¼šå…±äº«å‚æ•°ã€‚å…¶å®è¿™ä¸€éƒ¨åˆ†å¯ä»¥å‚è€ƒç°åœ¨çš„dynamic_rnnæ¥è¿›è¡Œç†è§£ï¼Œdynamic_rnnæ˜¯å¯¹æ¯ä¸ªbatchçš„æ•°æ®å°†å…¶padè‡³æœ¬batchä¸­é•¿åº¦æœ€å¤§çš„æ ·æœ¬ï¼Œè€Œbucketåˆ™æ˜¯åœ¨æ•°æ®é¢„å¤„ç†ç¯èŠ‚å…ˆå¯¹æ•°æ®é•¿åº¦è¿›è¡Œèšç±»æ“ä½œã€‚

æˆ‘ä»¬å†çœ‹ä¸€ä¸‹è¯¥å‡½æ•°çš„å‚æ•°å’Œå†…éƒ¨å®ç°ï¼š

```py
   encoder_inputs: encoderçš„è¾“å…¥ï¼Œä¸€ä¸ªtensorçš„åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æ¯ä¸€é¡¹éƒ½æ˜¯encoderæ—¶çš„ä¸€ä¸ªè¯ï¼ˆbatchï¼‰ã€‚
   decoder_inputs: decoderçš„è¾“å…¥ï¼ŒåŒä¸Š
   targets:        ç›®æ ‡å€¼ï¼Œä¸decoder_inputåªç›¸å·®ä¸€ä¸ª<EOS>ç¬¦å·ï¼Œint32å‹
   weights:        ç›®æ ‡åºåˆ—é•¿åº¦å€¼çš„maskæ ‡å¿—ï¼Œå¦‚æœæ˜¯paddingåˆ™weight=0ï¼Œå¦åˆ™weight=1
   buckets:        å°±æ˜¯å®šä¹‰çš„bucketå€¼ï¼Œæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼š[(5ï¼Œ10), (10ï¼Œ20),(20ï¼Œ30)...]
   seq2seq:        å®šä¹‰å¥½çš„seq2seqæ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨åé¢ä»‹ç»çš„embedding_attention_seq2seqï¼Œembedding_rnn_seq2seqï¼Œbasic_rnn_seq2seqç­‰
   softmax_loss_function: è®¡ç®—è¯¯å·®çš„å‡½æ•°ï¼Œ(labels, logits)ï¼Œé»˜è®¤ä¸ºsparse_softmax_cross_entropy_with_logits
   per_example_loss: å¦‚æœä¸ºçœŸï¼Œåˆ™è°ƒç”¨sequence_loss_by_exampleï¼Œè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶æ¯ä¸ªå…ƒç´ å°±æ˜¯ä¸€ä¸ªæ ·æœ¬çš„losså€¼ã€‚å¦‚æœä¸ºå‡ï¼Œåˆ™è°ƒç”¨sequence_losså‡½æ•°ï¼Œå¯¹ä¸€ä¸ªbatchçš„æ ·æœ¬åªè¿”å›ä¸€ä¸ªæ±‚å’Œçš„losså€¼ï¼Œå…·ä½“è§åé¢çš„åˆ†æ
   name: Optional name for this operation, defaults to "model_with_buckets".
```

å†…éƒ¨ä»£ç è¿™é‡Œä¸ä¼šå…¨éƒ¨è´´ä¸Šæ¥ï¼Œæ¡å…³é”®çš„è¯´ä¸€ä¸‹ï¼š

```py
#ä¿å­˜æ¯ä¸ªbucketå¯¹åº”çš„losså’Œoutput    
losses = []
outputs = []
with ops.name_scope(name, "model_with_buckets", all_inputs):
#å¯¹æ¯ä¸ªbucketéƒ½è¦é€‰æ‹©æ•°æ®è¿›è¡Œæ„å»ºæ¨¡å‹
for j, bucket in enumerate(buckets):
 #bucketsä¹‹é—´çš„å‚æ•°è¦è¿›è¡Œå¤ç”¨
 with variable_scope.variable_scope(variable_scope.get_variable_scope(), reuse=True if j > 0 else None):

   #è°ƒç”¨seq2seqè¿›è¡Œè§£ç å¾—åˆ°è¾“å‡ºï¼Œè¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œencoder_inputså’Œdecoder_inputsæ˜¯å®šä¹‰å¥½çš„placeholderï¼Œ
   #éƒ½æ˜¯é•¿åº¦ä¸ºåºåˆ—æœ€å¤§é•¿åº¦çš„åˆ—è¡¨ï¼ˆä¹Ÿå°±æ˜¯æœ€å¤§çš„é‚£ä¸ªbucketsçš„é•¿åº¦ï¼‰ï¼ŒæŒ‰ä¸Šé¢çš„ä¾‹å­ï¼Œè¿™ä¸¤ä¸ªplaceholderåˆ†åˆ«æ˜¯é•¿åº¦ä¸º20å’Œ30çš„åˆ—è¡¨ã€‚
   #åœ¨æ„å»ºæ¨¡å‹æ—¶ï¼Œå¯¹äºæ¯ä¸ªbucketï¼Œåªå–å…¶å¯¹åº”çš„é•¿åº¦ä¸ªplaceholderå³å¯ï¼Œå¦‚å¯¹äºï¼ˆ5,10ï¼‰è¿™ä¸ªbucketï¼Œå°±å–å‰5/10ä¸ªplaceholderè¿›è¡Œæ„å»ºæ¨¡å‹
   bucket_outputs, _ = seq2seq(encoder_inputs[:bucket[0]], decoder_inputs[:bucket[1]])
   outputs.append(bucket_outputs)
   #å¦‚æœæŒ‡å®šper_example_lossåˆ™è°ƒç”¨sequence_loss_by_exampleï¼Œlossesæ·»åŠ çš„æ˜¯ä¸€ä¸ªbatch_sizeå¤§å°çš„åˆ—è¡¨
   if per_example_loss:
     losses.append(
         sequence_loss_by_example(
             outputs[-1],
             targets[:bucket[1]],
             weights[:bucket[1]],
             softmax_loss_function=softmax_loss_function))
   #å¦åˆ™è°ƒç”¨sequence_lossï¼Œå¯¹ä¸Šé¢çš„ç»“æœè¿›è¡Œæ±‚å’Œï¼Œlossesæ·»åŠ çš„æ˜¯ä¸€ä¸ªå€¼
   else:
     losses.append(
         sequence_loss(
             outputs[-1],
             targets[:bucket[1]],
             weights[:bucket[1]],
             softmax_loss_function=softmax_loss_function))
```

å‡½æ•°çš„è¾“å‡ºä¸ºoutputså’Œlossesï¼Œå…¶tensorçš„shapeè§ä¸Šé¢è§£é‡Šã€‚
                              
## Reference

- [å®˜ç½‘ä»£ç ](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py)
- [Tensorflowæºç è§£è¯»ï¼ˆä¸€ï¼‰ï¼šAttention Seq2Seqæ¨¡å‹](https://zhuanlan.zhihu.com/p/27769667)
- [Chatbots with Seq2Seq](http://complx.me/2016-06-28-easy-seq2seq/)
- [tensorflowçš„legacy_seq2seq](https://lan2720.github.io/2017/03/10/tensorflow%E7%9A%84legacy-seq2seq/)
- [Neural Machine Translation (seq2seq) Tutorial](https://github.com/tensorflow/nmt#tips--tricks)
- [Tensorflowæ–°ç‰ˆSeq2Seqæ¥å£ä½¿ç”¨][1]

[1]: https://blog.csdn.net/thriving_fcl/article/details/74165062
[2]: https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py


