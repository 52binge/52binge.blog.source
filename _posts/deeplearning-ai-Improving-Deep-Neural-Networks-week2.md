---
title: Improving Deep Neural Networks (week2) - Optimization Algorithm
toc: true
date: 2018-07-21 10:00:21
categories: deeplearning
tags: deeplearning.ai
mathjax: true
---

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

Mini-batch、指数加权平均-偏差修正、Momentum、RMSprop、Adam、学习率衰减、局部最优

这节课每一节的知识点都很重要，所以本次笔记几乎涵盖了全部小视频课程的记录

<!-- more -->


## 1. Mini-batch

> 随机梯度下降法的一大缺点是, 你会失去所有向量化带给你的加速，因为一次性只处理了一个样本，这样效率过于低下, 所以实践中最好 选择不大不小 的 Mini-batch 尺寸. 实际上学习率达到最快，你会发现2个好处，你得到了大量向量化，另一方面 你不需要等待整个训练集被处理完，你就可以开始进行后续工作.
> 
> 它不会总朝着最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向. 它也不一定在很小的范围内收敛，如出现这个问题，你可以减小 学习率.
> 
> 样本集比较小，就没必要使用 mini-batch.
> 
> **经验值** ： 如果 m <= 2000, 可以使用 batch， 不然样本数目 m 较大，一般 mini-batch 大小设置为 64 or 128 or.. or 512..

**算法初步**

> 对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有500万或5000万的训练数据，处理速度就会比较慢。
>
> 但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为Mini-batch。

<img src="/images/deeplearning/C2W2-1_1.png" width="700" />

> 如图，以1000为单位，将数据划分，令 $x^{\\{1\\}}=\\{x^{(1)},x^{(2)}……x^{(5000)}\\}$, 一般用 $x^{ \\{ t \\} }$, $y^{ \\{t\\} }$ 表示划分后的 mini-batch.
> 
> 注意区分该系列教学视频的符号标记：
> - 小括号() 表示具体的某一个元素，指一个具体的值，例如 $x^{(i)}$
> - 中括号[] 表示神经网络中的某一层,例如 $Z^{[l]}$
> - 大括号{} 表示将数据细分后的一个集合,例如 $x^{\\{1\\}} = \\{x^{(1)},x^{(2)}……x^{(5000)}\\}$

**算法核心**

<img src="/images/deeplearning/C2W2-2_1.png" width="700" />

> 假设我们有5,000,000个数据，每1000作为一个集合，计入上面所提到的 $x^{\\{1\\}}=\\{x^{(1)},x^{(2)}……x^{(5000)}\\},……$

> 1. 需要迭代运行5000次神经网络运算.
> 2. 每一次迭代其实与之前笔记中所提到的计算过程一样，首先是前向传播，但是每次计算的数量是1000.
> 3. 计算损失函数，如果有正则化，则记得加上正则项
> 4. 反向传播
> 
> 注意，mini-batch相比于之前一次性计算所有数据不仅速度快，而且反向传播需要计算5000次，所以效果也更好.

epoch

> - 对于普通的梯度下降法，一个epoch只能进行一次梯度下降；
> - 对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降;

### 不同size大小的比较

普通的batch梯度下降法和Mini-batch梯度下降法代价函数的变化趋势，如下图所示：

<img src="/images/deeplearning/C2W2-3_1.png" width="700" />

**Batch梯度下降** （如下图中蓝色）:

> - 对所有m个训练样本执行一次梯度下降，每一次迭代时间较长；
> - Cost function 总是向减小的方向下降。

> 说明: mini-batch size = m，此时即为 Batch gradient descent $(x^{\{t\}},y^{\{t\}})=(X,Y)$

**随机梯度下降** （如下图中紫色）:

> -对每一个训练样本执行一次梯度下降，但是丢失了向量化带来的计算加速；
> - Cost function总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式.

> 说明: mini-batch size = 1，此时即为 Stochastic gradient descent $(x^{\\{t\\}},y^{\\{t\\}})=(x^{(i)},y^{(i)})$

**Mini-batch梯度下降** （如下图中绿色）:

> - 选一个 $1<size<m$ 的合适的 size 进行 Mini-batch 梯度下降，可实现快速学习，也应用了向量化带来的好处
> - Cost function 的下降处于前两者之间

<img src="/images/deeplearning/C2W2-4_1.png" width="700" />

### Mini-batch 大小的选择

> - 如果训练样本的大小比较小时，如 $m⩽2000$ 时 — 选择batch梯度下降法；
> - 如果训练样本的大小比较大时，典型的大小为：$2^{6}、2^{7}、\cdots、2^{10}$
> - Mini-batch的大小要符合 CPU/GPU 内存， 运算起来会更快一些.

## 2. Exponentially weighted averages

为了理解后面会提到的各种优化算法，我们需要用到指数加权平均，在统计学中也叫做指数加权移动平均.

指数加权平均的关键函数： 

$$
v\_{t} = \beta v\_{t-1}+(1-\beta)\theta\_{t}
$$

首先我们假设有一年的温度数据，如下图所示

<img src="/images/deeplearning/C2W2-5_0.jpg" width="500" />

我们现在需要计算出一个温度趋势曲线，计算方法(`指数加权平均实现`)如下：

$$
v\_{0} =0 \\\\
v\_{1}= \beta v\_{0}+(1-\beta)\theta\_{1} \\\\
v\_{2}= \beta v\_{1}+(1-\beta)\theta\_{2} \\\\
v\_{3}= \beta v\_{2}+(1-\beta)\theta\_{3} \\\\
\ldots
$$

> 上面的 $θ\_t$ 表示第 $t$ 天的温度，β 是可调节的参数，$V\_t$ 表示 $\frac{1}{1-β}$ 天的每日温度

<!--下图是一个关于天数和温度的散点图：
<img src="/images/deeplearning/C2W2-5_1.png" width="600" />
-->

### 当 β=0.9、0.98、0.5 的情况

当β=0.9时，指数加权平均最后的结果如下图中**红色**线所示；

<img src="/images/deeplearning/C2W2-5_2.jpg" width="600" />

当β=0.98时，指数加权平均最后的结果如下图中**绿色**线所示, 绿线相比较红线要平滑一些，是因为对过去温度的权重更大，所以当天天气温度的影响降低，在温度变化时，适应得更缓慢一些；

<img src="/images/deeplearning/C2W2-5_3.jpg" width="600" />

当β=0.5时，指数加权平均最后的结果如下图中**黄色**线所示；

<img src="/images/deeplearning/C2W2-5_4.jpg" width="600" />

<!--<img src="/images/deeplearning/C2W2-6_1.png" width="700" />
-->
>  Notes: The most common value for $\beta$ is 0.9.

### 理解指数加权平均

例子，当β=0.9时： 

$$
v\_{100} = 0.9v\_{99}+0.1\theta\_{100} \\\\ v\_{99} = 0.9v\_{98}+0.1\theta\_{99} \\\\ v\_{98} = 0.9v\_{97}+0.1\theta\_{98} \\\\
\ldots
$$

展开：

$$
v\_{100}=0.1\theta\_{100}+0.9(0.1\theta\_{99}+0.9(0.1\theta\_{98}+0.9v\_{97})) \\\\ v\_{100}=0.1\theta\_{100}+0.1\times0.9\theta\_{99}+0.1\times(0.9)^{2}\theta\_{98}+0.1\times(0.9)^{3}\theta\_{97}+\cdots
$$

上式中所有$θ$前面的系数相加起来为1或者接近于1，称之为偏差修正.

> 总体来说存在，$(1-\varepsilon)^{1/\varepsilon}=\dfrac{1}{e}$, 在我们的例子中，$1-\varepsilon=\beta=0.9$, 即 $0.9^{10}\approx 0.35\approx\dfrac{1}{e}$ . 相当于大约10天后，系数的峰值（这里是0.1）下降到原来的 $\dfrac{1}{e}$，只关注了过去10天的天气.

### 指数加权平均的偏差修正 Bias correction

在我们执行指数加权平均的公式时，当β=0.98时，得到的并不是图中的**绿色**曲线，而是下图中的**紫色**曲线，其起点比较低。

<img src="/images/deeplearning/C2W2-7.png" width="650" />

**原因**： 

> $$
v\_{0}=0\\\\v\_{1}=0.98v\_{0}+0.02\theta\_{1}=0.02\theta\_{1}\\\\v\_{2}=0.98v\_{1}+0.02\theta\_{2}=0.98\times0.02\theta\_{1}+0.02\theta\_{2}=0.0196\theta\_{1}+0.02\theta\_{2}
$$

> 如果第一天的值为如40，则得到的v1=0.02×40=0.8，则得到的值要远小于实际值，后面几天的情况也会由于初值引起的影响，均低于实际均值.

**偏差修正**： 

> 使用 $\dfrac{v\_{t}}{1-\beta^{t}}$

> - 当t=2时：

> $$
1-\beta^{t}=1-(0.98)^{2}=0.0396
$$

> $$
\dfrac{v\_{2}}{0.0396}=\dfrac{0.0196\theta\_{1}+0.02\theta\_{2}}{0.0396}
$$
> 
> 偏差修正得到了绿色的曲线，在开始的时候，能够得到比紫色曲线更好的计算平均的效果。随着t逐渐增大，$\beta^{t}$接近于0，所以后面绿色的曲线和紫色的曲线逐渐重合了.
>
> 虽然存在这种问题，但是在实际过程中，一般会忽略前期均值偏差的影响


**偏差修正 举个🌰, 以便于大家理解:**
 
> 首先我们假设的是 $β=0.98, V\_0=0$, 然后由 $V\_t=βV\_{t-1}+(1-β)θ\_t$ 可知
>
> - $V\_1=0.98V\_0+0.02θ\_1=0.02θ\_1$
>
> - $V\_2=0.98V\_1+0.02θ\_2=0.0196θ\_1+0.02θ\_2$
>
> 假设 $θ\_1=40℃$,那么 $V\_1=0.02*40=0.8℃$，这显然相差太大，同理对于后面的温度的计算也只会是变差越来越大. 所以我们需要进行偏差修正，具体方法如下：
>
> $$
V\_t=\frac{βV\_{t-1}+(1-β)θ\_t}{1-β^t}
$$
>
> 注意 ：！！！上面公式中的 $V\_{t-1}$ 是未修正的值.
> 
> 为方便说明，令 $β=0.98,θ\_1=40℃,θ\_2=39℃$, 则
> 
> - 当 $t=1,θ\_1=40℃$ 时，$V\_1=\frac{0.02*40}{1-0.98}=40$ ,哇哦, 有没有很巧的感觉，再看
> - 当 $t=2,θ\_2=39℃$ 时，$V\_2 = \frac{0.98\*V\_{t-1} + 0.02\*θ\_2}{1-0.98^2}$ $=\frac{0.98\*(0 + 0.02\*θ\_1)+0.02\*39}{1-0.98^2}=39.49$
> 
> 所以，记住你如果直接用修正后的 $V\_{t−1}$ 值代入计算就大错特错了.
>

## 3. Momentum

动量梯度下降的基本思想就是`计算梯度的指数加权平均数`，并利用该梯度来更新权重

在我们优化 Cost function 的时候，以下图所示的函数图为例：


在利用梯度下降法来最小化该函数的时候，每一次迭代所更新的代价函数值如图中蓝色线所示在上下波动，而这种幅度比较大波动，减缓了梯度下降的速度，而且我们只能使用一个较小的学习率来进行迭代.

如果用较大的学习率，结果可能会如紫色线一样偏离函数的范围，所以为了避免这种情况，只能用较小的学习率.

## 4. RMSprop

## 5. Adam (Adaptive Moment Estimation)



> Notes: Adam 优化算法 我会毫不犹豫的推荐给你， 它是 Momentum 和 RMSprop 的结合. 事实证明，它其实解决了很多问题.

## 6. Learning rate decay



## 7. 本周内容回顾

- 改善深层神经网络：超参数调试、正则化

## 8. Reference

- [网易云课堂 - deeplearning][1]
- [深度学习笔记：优化方法总结(BGD,SGD,Momentum,AdaGrad,RMSProp,Adam)][2]
- [Deep Learning 之 最优化方法][3]

[1]: https://study.163.com/my#/smarts
[2]: https://blog.csdn.net/u014595019/article/details/52989301
[3]: https://blog.csdn.net/BVL10101111/article/details/72614711

