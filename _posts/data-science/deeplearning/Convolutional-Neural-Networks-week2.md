---
title: Convolutional Neural Networks (week2) - deep CNN
date: 2018-08-24 20:00:21
categories: data-science
tags: deeplearning.ai
---

ç†è§£å¦‚ä½•æ­å»ºä¸€ä¸ªç¥ç»ç½‘ç»œï¼ŒåŒ…æ‹¬æœ€æ–°çš„å˜ä½“ï¼Œä¾‹å¦‚æ®‹ä½™ç½‘ç»œã€‚

<!-- more -->

## 1. Why look at case studies?

é€šè¿‡ä»–äººçš„å®ä¾‹å¯ä»¥æ›´å¥½çš„ç†è§£å¦‚ä½•æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œï¼Œæœ¬å‘¨è¯¾ç¨‹ä¸»è¦ä¼šä»‹ç»å¦‚ä¸‹ç½‘ç»œ

- LeNet-5
- AlexNet
- VGG
- ResNet (æœ‰152å±‚)
- Inception

## 2. Classic networks

### 2.1 LeNet-5

è¯¥ç½‘ç»œ 1980s æå‡ºï¼Œä¸»è¦é’ˆå¯¹ç°åº¦å›¾åƒè®­ç»ƒçš„ï¼Œç”¨äºè¯†åˆ«æ‰‹å†™æ•°å­—ã€‚

{% image "/images/deeplearning/C4W2-1_1.png", width="750px" %}

> 1. å½“æ—¶å¾ˆå°‘ç”¨åˆ° Paddingï¼Œæ‰€ä»¥çœ‹åˆ°éšç€ç½‘ç»œå±‚æ¬¡å¢åŠ ï¼Œå›¾åƒçš„é«˜åº¦å’Œå®½åº¦éƒ½æ˜¯é€æ¸å‡å°çš„ï¼Œæ·±åº¦åˆ™ä¸æ–­å¢åŠ .
> 2. å½“æ—¶äººä»¬ä¼šæ›´å€¾å‘äºä½¿ç”¨ Average Poolingï¼Œä½†æ˜¯ç°åœ¨åˆ™æ›´æ¨èä½¿ç”¨ Max Pooling.
> 3. æœ€åçš„é¢„æµ‹æ²¡æœ‰ä½¿ç”¨ softmaxï¼Œè€Œæ˜¯ä½¿ç”¨äº†ä¸€èˆ¬çš„æ–¹æ³•.
>
> è®ºæ–‡ä¸­ä½ ä¼šå‘ç°ï¼Œè¿‡å»äººä»¬ä½¿ç”¨ Sigmoidå‡½æ•° å’Œ Tanhå‡½æ•°ï¼Œè€Œä¸æ˜¯ ReLuï¼Œ è¿™ç§ç½‘è·¯ç»“æ„çš„ç‰¹åˆ«ä¹‹å¤„è¿˜åœ¨äºå„ç½‘ç»œå±‚ä¹‹é—´æ˜¯æœ‰å…³è”çš„.

### 2.2 AlexNet

AlexNet å…¶å®å’Œ LetNet-5 æœ‰å¾ˆå¤šç›¸ä¼¼çš„åœ°æ–¹ï¼Œå¦‚å¤§è‡´çš„ç½‘ç»œç»“æ„ã€‚ä¸åŒçš„åœ°æ–¹ä¸»è¦æœ‰å¦‚ä¸‹ï¼š

{% image "/images/deeplearning/C4W2-2_1.png", width="750px" %}

- æ¿€æ´»å‡½æ•°ä½¿ç”¨çš„æ˜¯ **Relu**ï¼Œæœ€åä¸€å±‚ä½¿ç”¨çš„æ˜¯ **Softmax**
- å‚æ•°æ›´å¤šï¼Œæœ‰6000ä¸‡ä¸ªå‚æ•°ï¼Œè€Œ LeNet-5 åªæœ‰6ä¸‡ä¸ªå·¦å³
- ä½¿ç”¨ Max Pooling

> Local Response Normalization å±€éƒ¨å“åº”å½’ä¸€åŒ– - LRNå±‚ï¼Œä¸é‡è¦åˆ’æ‰.
> 
> è¿™ç¯‡è®ºæ–‡ä¹‹åï¼Œæ·±åº¦å­¦ä¹ é€æ¸åœ¨ CV æ–¹é¢çš„å…³æ³¨ï¼Œä¸æ—¥ä¿±å¢. 
> 
> AlexNet æ¯”è¾ƒå¤æ‚ï¼ŒåŒ…å«å¤§é‡è¶…å‚æ•°.

### 2.3 VGG-16

{% image "/images/deeplearning/C4W2-3_1.png", width="750px" %}

è¿™ä¸ªç½‘ç»œå¤ªç‰›äº†ï¼Œå› ä¸ºå®ƒæœ‰å°†è¿‘ 1.38äº¿ä¸ªå‚æ•°ï¼Œå³ä½¿æ”¾åˆ°ç°åœ¨ä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ç½‘ç»œï¼Œä½†æ˜¯è¿™ä¸ªç½‘ç»œçš„ç»“æ„å¹¶ä¸å¤æ‚ã€‚ä¸‹é¢ä¸»è¦ä»‹ç»ä¸€ä¸‹ä¸Šå›¾ç½‘ç»œã€‚

é¦–å…ˆè¯¥ç½‘ç»œä½¿ç”¨çš„æ˜¯ Sameå·ç§¯ï¼Œå³ä¿è¯é«˜åº¦å’Œå®½åº¦ä¸å˜ï¼Œå¦å¤–å› ä¸ºæ€»å…±æœ‰16å±‚å·ç§¯æ“ä½œï¼Œæ‰€ä»¥å°±ä¸æŠŠæ¯ä¸€å±‚éƒ½ç”¨å›¾åƒçš„æ–¹å¼è¡¨ç°å‡ºæ¥äº†ï¼Œä¾‹å¦‚ [CONV 64 X2] è¡¨ç¤ºçš„æ˜¯ç”¨ 64ä¸ª è¿‡æ»¤å™¨è¿›è¡Œ Sameå·ç§¯ æ“ä½œ2æ¬¡ï¼Œå³å³ä¸Šè§’æ‰€ç”»çš„ç¤ºæ„å›¾ï¼Œ(224,224,3) -> (224,224,64) -> (224,224,64)

> **Andrew Ng** : æˆ‘æœ€å–œæ¬¢å®ƒçš„ä¸€ç‚¹æ˜¯ï¼Œéšç€ç½‘ç»œçš„åŠ æ·±ï¼Œå›¾åƒçš„ Height å’Œ Width éƒ½åœ¨ä»¥ä¸€å®šçš„è§„å¾‹ä¸æ–­ç¼©å°ï¼Œæ¯æ¬¡æ± åŒ–ä¹‹ååˆšå¥½ç¼©å°ä¸€åŠï¼Œè€Œä¿¡é“æ•°é‡åœ¨ä¸æ–­å¢åŠ . è€Œåˆšå¥½ä¹Ÿæ˜¯åœ¨æ¯ç»„å·ç§¯æ“ä½œåå¢åŠ ä¸€å€. ä¹Ÿå°±æ˜¯è¯´ ï¼š å›¾åƒç¼©å°çš„æ¯”ä¾‹å’Œä¿¡é“å¢åŠ çš„æ¯”ä¾‹æ˜¯æœ‰è§„å¾‹çš„.
> 
> ä¸Šé¢ä¸‰ä¸ªæ˜¯æ¯”è¾ƒç»å…¸çš„ç½‘ç»œï¼Œå¯é˜…è¯»å…¶è®ºæ–‡ï¼ŒNg**å´å¤§å¸ˆ** å»ºè®®çš„é˜…è¯»é¡ºåºæ˜¯ AlexNet->VGG->LeNetã€‚

## 3. Residual Network (ResNets)

ResNets å‘æ˜è€…æ˜¯ ä½•æºæ˜ã€å¼ ç¿”å®‡ã€ä»»å°‘å¿ã€å­™å‰‘

å´å¤§å¸ˆè¡¨ç¤º â€œéå¸¸æ·±çš„ç½‘ç»œæ˜¯å¾ˆéš¾è®­ç»ƒçš„ï¼Œå› ä¸ºå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜â€ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¼•å…¥äº† **Skip Connection** (è·³è¿œé“¾æ¥)ï¼Œæ®‹å·®ç½‘ç»œæ­£æ˜¯ä½¿ç”¨äº†è¿™ä¸ªæ–¹æ³•ã€‚

### 3.1 æ®‹å·®å— (Residual Block)

é¦–å…ˆä»‹ç»ç»„æˆæ®‹å·®ç½‘ç»œçš„å•å…ƒï¼šæ®‹å·®å—(**Residual Block**)ï¼Œå¦‚ä¸‹å›¾ç¤ºï¼š

{% image "/images/deeplearning/C4W2-4.png", width="550px" %}

æ®‹å·®å—æ˜¯ç”±ä¸¤å±‚ç½‘ç»œèŠ‚ç‚¹ç»„æˆçš„, $a^{[l]}$ ç»è¿‡çº¿æ€§å˜åŒ–ï¼Œå†é€šè¿‡Reluæ¿€æ´»å‡½æ•°åå¾—åˆ° $a^{[l+1]}$ï¼Œ $a^{[l+2]}$ ä¹ŸåŒç†ï¼Œå…·ä½“è¿‡ç¨‹å¦‚ä¸‹å›¾ç¤ºï¼š

{% image "/images/deeplearning/C4W2-5_1.png", width="750px" %}

ç‰¹åˆ«æ³¨æ„ä¸Šå›¾ä¸­çš„**ç´«è‰²çº¿**è¿æ¥ï¼Œ$a^{[{l}]}$ é€šè¿‡è¿™æ¡çº¿ç›´æ¥å°†æ•°æ®ä¼ é€’ç»™ $a^{[l+2]}$ï¼Œ æ‰€ä»¥ $a^{[l+2]}=g(z^{[l+1]}+a^{[l]})$ ï¼Œè¿™æ¡ç´«è‰²çº¿ä¹Ÿå«ä½œ**short cut**(æˆ–skip connection)

### 3.2 æ®‹å·®ç½‘ç»œ

{% image "/images/deeplearning/C4W2-6_1.png", width="750px" %}

å¦‚å›¾ç¤ºï¼Œæ®‹å·®ç½‘ç»œæ¯ä¸¤å±‚ç½‘ç»œèŠ‚ç‚¹ç»„æˆä¸€ä¸ªæ®‹å·®å—ï¼Œè¿™ä¹Ÿå°±æ˜¯å…¶ä¸æ™®é€šç½‘ç»œ(Plain Network)çš„å·®åˆ«ã€‚

éšç€ç½‘ç»œæ·±åº¦çš„åŠ æ·±ï¼Œä¼˜åŒ–ç®—æ³•ä¼šè¶Šæ¥è¶Šéš¾è®­ç»ƒï¼Œè®­ç»ƒé”™è¯¯ä¼šè¶Šæ¥è¶Šå¤šï¼Œä½†æ˜¯æœ‰äº† ResNets å°±ä¸ä¸€æ ·äº†. ä¹Ÿå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜. å¦ä¸€è§’åº¦ï¼Œç½‘ç»œè¶Šæ·±ä¼šæ¯”è¾ƒè‡ƒè‚¿ï¼Œä½†æ˜¯ ResNet ç¡®å®åœ¨è®­ç»ƒæ·±åº¦ç½‘ç»œæ–¹é¢éå¸¸æœ‰æ•ˆ.

ç»“åˆä¹‹å‰çš„è¯¾ç¨‹æˆ‘ä»¬çŸ¥é“å¦‚æœä½¿ç”¨æ™®é€šç½‘ç»œè®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒè¯¯å·®ä¼šéšç€ç½‘ç»œå±‚æ¬¡åŠ æ·±å…ˆå‡å°ï¼Œè€Œåä¼šå¼€å§‹å¢åŠ ï¼Œè€Œæ®‹å·®ç½‘ç»œåˆ™ä¸ä¼šæœ‰è¿™ç§æƒ…å†µï¼Œåè€Œå®ƒä¼šéšç€å±‚æ¬¡å¢åŠ ï¼Œè¯¯å·®ä¹Ÿä¼šè¶Šæ¥è¶Šå°ï¼Œè¿™ä¸ç†è®ºç›¸ç¬¦ã€‚

éšç€ç½‘ç»œæ·±åº¦çš„åŠ æ·±ï¼Œä¼˜åŒ–ç®—æ³•ä¼šè¶Šæ¥è¶Šéš¾è®­ç»ƒï¼Œè®­ç»ƒé”™è¯¯ä¼šè¶Šæ¥è¶Šå¤šï¼Œä½†æ˜¯æœ‰äº† ResNets å°±ä¸ä¸€æ ·äº†. ä¹Ÿå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜. å¦ä¸€è§’åº¦ï¼Œç½‘ç»œè¶Šæ·±ä¼šæ¯”è¾ƒè‡ƒè‚¿ï¼Œä½†æ˜¯ ResNet ç¡®å®åœ¨è®­ç»ƒæ·±åº¦ç½‘ç»œæ–¹é¢éå¸¸æœ‰æ•ˆ.

## 4. Why ResNets work

å´å¤§è¡¨ç¤º: ç½‘ç»œåœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¥½ï¼Œæ‰èƒ½ Hold-out äº¤å‰éªŒè¯é›† æˆ– devé›†ã€æµ‹è¯•é›†ä¸Šè¡¨ç°å¥½ï¼Œæ‰€ä»¥è®­ç»ƒé›†ä¸Šè¡¨ç°å¥½æ˜¯ç¬¬ä¸€æ­¥.

ä¸ºäº†ç›´è§‚è§£é‡Šæ®‹å·®ç½‘ç»œä¸ºä»€ä¹ˆæœ‰ç”¨ï¼Œå‡è®¾æˆ‘ä»¬å·²ç»é€šè¿‡ä¸€ä¸ªå¾ˆå¤§çš„ç¥ç»ç½‘ç»œå¾—åˆ°äº† $a^{[l]}$ã€‚ è€Œç°åœ¨æˆ‘ä»¬åˆéœ€è¦æ·»åŠ ä¸¤å±‚ç½‘ç»œè¿›å»ï¼Œæˆ‘ä»¬çœ‹çœ‹å¦‚æœæ·»åŠ çš„æ˜¯æ®‹å·®å—ä¼šæœ‰ä»€ä¹ˆæ•ˆæœã€‚å¦‚ä¸‹å›¾ç¤ºï¼š

{% image "/images/deeplearning/C4W2-7.jpg", width="650px" %}

ç”± **æ®‹å·®å—Residual Block** çš„ç‰¹ç‚¹æˆ‘ä»¬çŸ¥é“ $a^{[l+2]}=g(z^{[l+1]}+a^{[l]})=g(W^{[l+1]}a^{[l]}+b^{[l+1]}+a^{[l]})$

æˆ‘ä»¬å…ˆè€ƒè™‘ä¸€ä¸ªæç«¯æƒ…å†µï¼Œå³ $W^{[l+1]}=0,b^{[l+1]}=0$ï¼Œ é‚£ä¹ˆ $a^{[l+2]}=g(a^{[l]})=a^{[l]}$ **(å› ä¸ºæ¿€æ´»å‡½æ•°æ˜¯Relu)**ï¼Œæ‰€ä»¥åœ¨æ·»åŠ äº†é¢å¤–çš„ä¸¤å±‚ç½‘ç»œåï¼Œå³ä½¿æœ€åæƒ…å†µä¹Ÿæ˜¯ä¿æŒå’Œä¹‹å‰ç»“æœä¸€æ ·ã€‚(è€Œå¦‚æœåªæ˜¯**åŠ ä¸Šæ™®é€šçš„ä¸¤å±‚ç½‘ç»œ**ï¼Œå¯èƒ½ç»“æœä¼šæ›´å¥½ï¼Œä½†æ˜¯ä¹Ÿå¾ˆæœ‰å¯èƒ½ç»“æœä¼šè¶Šæ¥è¶Šç³Ÿç³•, å› ä¸ºæ™®é€šç½‘ç»œå°±ç®—æ˜¯é€‰æ‹©ç”¨æ¥å­¦ä¹ æ’ç­‰å‡½æ•°çš„å‚æ•°éƒ½å¾ˆå›°éš¾)ï¼Œæ®‹å·®ç½‘ç»œèµ·ä½œç”¨çš„ä¸»è¦åŸå› æ˜¯è¿™äº›æ®‹å·®å—å­¦ä¹ æ’ç­‰å‡½æ•°éå¸¸å®¹æ˜“, è¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆæ®‹å·®ç½‘ç»œèƒ½å¤Ÿä¿è¯æ·±åº¦ç½‘ç»œä¾æ—§æœ‰ç”¨çš„åŸå› äº†ã€‚

> **æ³¨æ„** ï¼š å„å±‚ç½‘ç»œçš„**ç»´åº¦**ï¼Œå› ä¸º $a^{[l+2]}=g(z^{[l+1]}+a^{[l]})$, é‚£ä¹ˆå°±è¦æ±‚ $z^{[l+1]}$ è¦å’Œ $a^{[l]}$ ä¿æŒç›¸åŒçš„ç»´åº¦æ‰€ä»¥æ®‹å·®ç½‘ç»œä½¿ç”¨çš„æ˜¯**Sameå·ç§¯**ã€‚
>
> ä½†æ˜¯å¦‚æœå”¯ç‹¬ä¸ä¸€æ ·ä¹Ÿæ²¡å…³ç³»ï¼Œå¯ä»¥ç»™ $a^{[l]}$ ä¹˜ä¸Šä¸€ä¸ª $W\_s$ æ¥ä¿æŒç›¸åŒç»´åº¦ã€‚ $W\_s$ çš„å€¼å¯ä»¥é€šè¿‡å­¦ä¹ è·å¾—
> 
> æ™®é€šç½‘ç»œ å’Œ ResNets å¸¸ç”¨çš„ç»“æ„æ˜¯ Conv -> Conv -> Conv -> Pool -> Conv -> Conv -> Conv -> Pool ä¾æ¬¡é‡å¤ä¹‹.. ç›´åˆ°æœ‰ä¸€ä¸ªé€šè¿‡ Softmax è¿›è¡Œé¢„æµ‹çš„å…¨è¿æ¥å±‚.

## 5. in Network and 1Ã—1 convolutions

$1 \* 1$ å·ç§¯ä¹çœ‹èµ·æ¥å¥½åƒå¾ˆæ²¡ç”¨ï¼Œå¦‚ä¸‹å›¾ä¸Šï¼Œâ€‹ä½†æ˜¯å¦‚æœè¿™ä¸ª $1 \* 1$ çš„å·ç§¯æœ‰æ·±åº¦å‘¢ï¼Ÿâ€‹

{% image "/images/deeplearning/C4W2-8.png", width="750px" %}

è¯´ä¸ªæ›´åŠ ç›´è§‚çš„ç†è§£å°±æ˜¯ä½¿ç”¨ $1\*1$ å·ç§¯å¯ä»¥å¾ˆæ–¹ä¾¿çš„å‡å°‘æ·±åº¦ï¼Œè€Œä¸æ”¹å˜é«˜åº¦å’Œå®½åº¦ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

{% image "/images/deeplearning/C4W2-9.png", width="700px" %}

åªéœ€è¦ç”¨ 32 ä¸ª ($1\*1\*192$) çš„ Filter å³å¯, å¦‚æœä¸ç”¨ $1 \* 1$ å·ç§¯ï¼Œä¾‹å¦‚é‡‡ç”¨ $2\*2$ å·ç§¯,è¦æƒ³å®ç°åªæ”¹å˜æ·±åº¦ï¼Œé‚£ä¹ˆè¿˜éœ€è¦ä½¿ç”¨ paddingï¼Œç›¸æ¯”èµ·æ¥æ›´åŠ éº»çƒ¦äº†.

## 6. Inception network motivation

{% image "/images/deeplearning/C4W2-10.jpg", width="700px" %}

å¦‚ä¸Šå›¾ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å„ç§è¿‡æ»¤å™¨ï¼Œä¹Ÿæ˜¯ç”¨äº† Max Poolingã€‚ä½†æ˜¯è¿™äº›å¹¶ä¸éœ€è¦äººå·¥çš„é€‰æ‹©å…¶ä¸ªæ•°ï¼Œè¿™äº›éƒ½å¯ä»¥é€šè¿‡å­¦ä¹ æ¥ç¡®å®šä¸‹æ¥ã€‚æ‰€ä»¥è¿™ç§æ–¹æ³•å¾ˆå¥½çš„å¸®åŠ©æˆ‘ä»¬é€‰æ‹©ä½•ç§ **Filter** çš„é—®é¢˜ï¼Œè¿™ä¹Ÿå°±æ˜¯ **Inception**ç½‘ç»œã€‚

### 6.1 è®¡ç®—æˆæœ¬

æ³¨æ„éšä¹‹è€Œæ¥çš„è®¡ç®—æˆæœ¬ï¼Œå°¤å…¶æ˜¯ $5\*5$ çš„ Filterï¼Œä¸‹é¢ä»¥è¿™ä¸ª Filter ä¸¾ä¾‹è¿›è¡Œè¯´æ˜ï¼š

{% image "/images/deeplearning/C4W2-11.jpg", width="700px" %}

å¦‚ä¸Šå›¾ç¤ºï¼Œä½¿ç”¨ 32 ä¸ª $(5\*5\*192)$ çš„ **Filter**ï¼Œå¯¹ $(28,28,192)$ è¿›è¡Œ Sameå·ç§¯ è¿ç®—å¾—åˆ° $(28,28,32)$ çš„è¾“å‡ºçŸ©é˜µï¼Œè¯¥å·ç§¯éœ€è¦æ‰§è¡Œçš„ä¹˜æ³•è¿ç®—æœ‰å¤šå°‘æ¬¡å‘¢ï¼Ÿ

è¾“å‡ºçŸ©é˜µä¸­çš„ä¸€ä¸ªæ•°æ®æ˜¯ç»è¿‡ $(5\*5\*192)$ æ¬¡ä¹˜æ³•å¾—åˆ°çš„ï¼Œé‚£ä¹ˆæ€»å…±çš„ä¹˜æ³•è¿ç®—æ¬¡æ•°åˆ™æ˜¯ $(5\*5\*192\*28\*28\*32=1.2)$ äº¿

### 6.2 ç“¶é¢ˆå±‚(Bottleneck layer)

ä¸Šé¢è¿ç®—æ¬¡æ•°å¤šå¤§1.2äº¿æ¬¡ï¼Œè¿ç®—é‡ç›¸å½“å¤§ï¼Œå› æ­¤æœ‰å¦ä¸€ç§ç½‘ç»œç»“æ„å¯¹æ­¤è¿›è¡Œä¼˜åŒ–ï¼Œä¸”å¯ä»¥è¾¾åˆ°åŒæ ·æ•ˆæœï¼Œå³é‡‡ç”¨ 1 \* 1 å·ç§¯

{% image "/images/deeplearning/C4W2-12.png", width="700px" %}

å¦‚å›¾ç¤ºè¿›è¡Œäº†ä¸¤æ¬¡å·ç§¯ï¼Œæˆ‘ä»¬è®¡ç®—ä¸€ä¸‹æ€»å…±çš„ä¹˜æ³•æ¬¡æ•°ã€‚

ç¬¬ä¸€æ¬¡å·ç§¯ï¼š28 \* 28 \* 16 \* 192 = 2.4 million
ç¬¬äºŒæ¬¡å·ç§¯ï¼š28 \* 28 \* 32 \* 5 \* 5 \* 16 = 10 million
æ€»å…±ä¹˜æ³•æ¬¡æ•°æ˜¯ 12.4 millionï¼Œè¿™ä¸ä¸Šé¢ç›´æ¥ç”¨ 5 \* 5 Filter çš„è¿ç®—æ¬¡æ•°æ•´æ•´å°‘äº†åå€ã€‚

## 7. Inception network

{% image "/images/deeplearning/C4W2-12_1.png", width="750px" %}

{% image "/images/deeplearning/C4W2-13_1.png", width="750px" %}

> ä¸ºäº†å¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œè¿˜æœ‰ä¸ªç‰¹åˆ«çš„ inception networkï¼Œæ˜¯ä¸€ä¸ª Google å‘˜å·¥å¼€å‘çš„å«åš GoogLeNetï¼Œè¿™ä¸ªåå­—æ˜¯ä¸ºäº†å‘ LeNet è‡´æ•¬. è¿™æ ·éå¸¸å¥½ï¼Œæ·±åº¦å­¦ä¹ çš„ç ”ç©¶äººå‘˜å¦‚ä½•é‡è§†åä½œï¼Œæ·±åº¦å­¦ä¹ å·¥ä½œè€…å¯¹å½¼æ­¤çš„å·¥ä½œæˆæœï¼Œéƒ½æœ‰ä¸€ç§å¼ºçƒˆçš„æ•¬æ„.

## 8. Using open-source impl

Practical advice for using ConvNets

## 9. Transfer Learning

ç®€å•è¯´å°±æ˜¯åœ¨ä»–äººçš„åŸºç¡€ä¸Šå®ç°è‡ªå·±æƒ³è¦çš„æ¨¡å‹ï¼Œä¸¾ä¸ªğŸŒ°ï¼Œå‡å¦‚æˆ‘ä»¬ç°åœ¨éœ€è¦è¯†åˆ«å®¶é‡Œå…»çš„ä¸¤åªçŒ«ï¼Œåˆ†åˆ«å« **å°èŠ±** å’Œ **å°ç™½**ï¼Œä½†æ˜¯æˆ‘ä»¬åªæœ‰æ¯”è¾ƒå°‘çš„å›¾ç‰‡ã€‚å¹¸è¿çš„æ˜¯ç½‘ä¸Šå·²ç»æœ‰ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ˜¯ç”¨æ¥åŒºåˆ†1000ä¸ªä¸åŒäº‹ç‰©çš„(åŒ…æ‹¬çŒ«)ï¼Œå…¶ç½‘ç»œæ¨¡å‹å¦‚ä¸‹ï¼š

{% image "/images/deeplearning/C4W2-15.png", width="750px" %}

æˆ‘ä»¬çš„éœ€æ±‚æ˜¯æœ€åç»“æœæœ‰ä¸‰ç§ï¼šæ˜¯ **å°èŠ±**ï¼Œor **å°ç™½**ï¼Œor **éƒ½ä¸æ˜¯**ã€‚â€‹æ‰€ä»¥éœ€è¦å¯¹ **softmax** åšå¦‚ä¸‹å›¾ä¿®æ”¹.

ç”±äºæ•°æ®è¾ƒå°‘ï¼Œæ‰€ä»¥å¯ä»¥å¯¹ä»–äººçš„æ¨¡å‹çš„å‰é¢çš„ç»“æ„ä¸­çš„å‚æ•°è¿›è¡Œå†»ç»“ï¼Œå³ **æƒé‡ weight** å’Œ **åå·® bias** ä¸åšæ”¹åŠ¨ã€‚

{% image "/images/deeplearning/C4W2-16.png", width="750px" %}

â€‹å½“ç„¶ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€å®šé‡çš„æ•°æ®ï¼Œé‚£ä¹ˆ **freeze** çš„èŒƒå›´ä¹Ÿå¯ä»¥éšä¹‹å‡å°‘ï¼Œå³æ‹¿æ¥è®­ç»ƒçš„å±‚æ¬¡å¯ä»¥å¢å¤š
â€‹
â€‹{% image "/images/deeplearning/C4W2-17.png", width="750px" %}

> you find that for a lot of computer vision applications, you just do much better if you download someone else's open source weights and use that as initialization for your problem.
> 
> I think that computer vision is one where transfer learning is something that you should almost always do. ï¼ˆunless you actually have a very very large data set..ï¼‰

## 10. Data augmentation

### 10.1 Common augmentation

- æ—‹è½¬(rotation)
- ä¿®å‰ª(shearing)
- å±€éƒ¨å˜å½¢(local warping)
- é•œåƒ(mirroring)

â€‹{% image "/images/deeplearning/C4W2-18.jpg", width="750px" %}

> ä»¥ä¸Šä»‹ç»çš„æ–¹æ³•ï¼ŒåŒæ—¶ä½¿ç”¨å¹¶æ²¡æœ‰ä»€ä¹ˆåå¤„ï¼Œä½†æ˜¯åœ¨å®è·µä¸­ï¼Œå› ä¸ºå¤ªå¤æ‚äº†ï¼Œæ‰€ä»¥ä½¿ç”¨çš„å¾ˆå°‘ã€‚
>
> æ›´ç»å¸¸ä½¿ç”¨çš„æ–¹æ³•å¯èƒ½ä¸‹é¢è¦ä»‹ç»çš„ **Color shifting** ã€‚

### 10.2 Color shifting

æˆ‘ä»¬éƒ½çŸ¥é“å›¾åƒæ˜¯ç”± **RGB** ä¸‰ç§é¢œè‰²æ„æˆçš„ï¼Œæ‰€ä»¥è¯¥æ•°æ®æ‰©å……æ–¹æ³•å¸¸é‡‡ç”¨ **PCA color augmentation**ï¼Œå³å‡å¦‚ä¸€ä¸ªå›¾ç‰‡çš„ **R** å’Œ **G** æˆåˆ†è¾ƒå¤šï¼Œé‚£ä¹ˆè¯¥ç®—æ³•åˆ™ **R,G** çš„å€¼ä¼šå‡å°‘å¾ˆå¤šï¼Œè€Œ B çš„å€¼å˜åŒ–ä¼šå°‘ä¸€äº›ï¼Œæ‰€ä»¥ä½¿å¾—æ€»ä½“çš„é¢œè‰²ä¿æŒä¸€è‡´.

â€‹{% image "/images/deeplearning/C4W2-19_2.png", width="750px" %}

> å¦‚æœä½ çœ‹ä¸æ‡‚è¿™äº›ï¼Œé‚£ä¹ˆæ²¡å…³ç³»ï¼Œå¯ä»¥çœ‹çœ‹ AlexNet è®ºæ–‡ä¸­çš„ç»†èŠ‚ï¼Œä½ ä¹Ÿèƒ½æ‰¾åˆ° PCA é¢œè‰²å¢å¼ºçš„å¼€æºå®ç°æ–¹æ³•.

## 11. The state of CV

â€‹{% image "/images/deeplearning/C4W2-21_1.png", width="750px" %}

â€‹{% image "/images/deeplearning/C4W2-22_1.png", width="750px" %}

â€‹{% image "/images/deeplearning/C4W2-23_1.png", width="750px" %}
â€‹
## Reference

- [ç½‘æ˜“äº‘è¯¾å ‚ - deeplearning][1]
- [DeepLearning.aiå­¦ä¹ ç¬”è®°æ±‡æ€»][2]

[1]: https://study.163.com/my#/smarts
[2]: http://www.cnblogs.com/marsggbo/p/7470989.html
